#!/usr/bin/env python3
"""
PARALLAX CONTROLLER v2.0
Orquestrador global para cluster Arkhe(n) distribu√≠do
Implementa scheduling Hebbiano e balanceamento de carga biol√≥gico
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
import numpy as np

import zmq
import zmq.asyncio
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import StreamingResponse
try:
    import redis.asyncio as redis
except ImportError:
    # Fallback for systems where redis-py is older or not installed
    redis = None

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Parallax.Controller")

@dataclass
class ArkheNode:
    """Representa um n√≥ Arkhe(n) no cluster"""
    node_id: str
    hostname: str
    address: str
    port: int
    partition: Tuple[int, int, int]  # Octante 3D atribu√≠do
    resources: Dict[str, float] = field(default_factory=dict)
    agents_count: int = 0
    health_score: float = 1.0
    last_heartbeat: float = 0.0
    is_active: bool = False

    # M√©tricas de performance
    avg_latency_ms: float = 0.0
    throughput: float = 0.0  # agentes/tick

class ParallaxController:
    """
    Controller central estilo Parallax para orquestra√ß√£o de n√≥s Arkhe(n)
    """

    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.nodes: Dict[str, ArkheNode] = {}
        self.redis: Optional[Any] = None
        self.redis_url = redis_url

        # Contexto ZeroMQ para comunica√ß√£o de alta performance
        self.zmq_context = zmq.asyncio.Context()
        self.command_socket = None  # PUB para comandos globais
        self.metrics_socket = None  # PULL para m√©tricas dos n√≥s

        # Estado do campo global (visualiza√ß√£o apenas)
        self.global_field_stats = {
            'total_agents': 0,
            'total_bonds': 0,
            'avg_health': 0.0,
            'field_entropy': 0.0
        }

        # Configura√ß√µes de particionamento
        self.halo_size = 5  # C√©lulas de sobreposi√ß√£o entre n√≥s
        self.space_size = (100, 100, 100)  # Tamanho total do campo

        self.running = False

    async def initialize(self):
        """Inicializa o controller"""
        logger.info("üéõÔ∏è  Inicializando Parallax Controller v2.0")

        # Conecta ao Redis
        if redis:
            try:
                self.redis = await redis.from_url(self.redis_url, decode_responses=True)
                await self.redis.ping()
                logger.info("   ‚úì Redis conectado")
            except Exception as e:
                logger.error(f"   ‚úó Falha no Redis: {e}")
                # We can continue without redis for non-persistence features

        # Inicializa sockets ZeroMQ
        self.command_socket = self.zmq_context.socket(zmq.PUB)
        self.command_socket.bind("tcp://*:5555")

        self.metrics_socket = self.zmq_context.socket(zmq.PULL)
        self.metrics_socket.bind("tcp://*:5556")

        logger.info("   ‚úì ZeroMQ ativo (PUB:5555, PULL:5556)")

        # Agenda tarefas de background
        asyncio.create_task(self.heartbeat_monitor())
        asyncio.create_task(self.metrics_collector())
        asyncio.create_task(self.load_balancer())

        self.running = True
        logger.info("‚úÖ Controller operacional")

    async def register_node(self, node: ArkheNode) -> bool:
        """Registra um novo n√≥ no cluster"""
        # Verifica se h√° conflito de parti√ß√£o
        for existing in self.nodes.values():
            if existing.partition == node.partition and existing.is_active:
                logger.warning(f"Conflito de parti√ß√£o: {node.node_id} vs {existing.node_id}")
                return False

        self.nodes[node.node_id] = node

        # Publica no Redis para descoberta
        if self.redis:
            await self.redis.hset(f"parallax:node:{node.node_id}", mapping={
                'hostname': node.hostname,
                'address': node.address,
                'partition': json.dumps(node.partition),
                'agents': node.agents_count,
                'health': node.health_score
            })

        logger.info(f"üñ•Ô∏è  N√≥ registrado: {node.node_id} @ {node.address} "
                   f"(parti√ß√£o {node.partition})")
        return True

    async def unregister_node(self, node_id: str):
        """Remove n√≥ do cluster"""
        if node_id in self.nodes:
            node = self.nodes.pop(node_id)
            if self.redis:
                await self.redis.delete(f"parallax:node:{node_id}")
            logger.info(f"üñ•Ô∏è  N√≥ removido: {node_id}")

    async def heartbeat_monitor(self):
        """Monitora sa√∫de dos n√≥s via heartbeat"""
        while self.running:
            current_time = time.time()
            dead_nodes = []

            for node_id, node in self.nodes.items():
                if current_time - node.last_heartbeat > 30:  # 30s timeout
                    logger.warning(f"üíî Heartbeat perdido: {node_id}")
                    node.is_active = False
                    dead_nodes.append(node_id)

            # Tenta recuperar ou realoca n√≥s mortos
            for node_id in dead_nodes:
                await self.handle_node_failure(node_id)

            await asyncio.sleep(5)

    async def metrics_collector(self):
        """Coleta m√©tricas dos n√≥s via ZeroMQ"""
        while self.running:
            try:
                # Non-blocking receive com timeout
                if await self.metrics_socket.poll(timeout=1000):
                    msg = await self.metrics_socket.recv_json()
                    node_id = msg.get('node_id')

                    if node_id in self.nodes:
                        node = self.nodes[node_id]
                        node.agents_count = msg.get('agents', 0)
                        node.health_score = msg.get('health', 1.0)
                        node.last_heartbeat = time.time()
                        node.is_active = True
                        node.avg_latency_ms = msg.get('latency_ms', 0)

                        # Atualiza Redis
                        if self.redis:
                            await self.redis.hset(f"parallax:node:{node_id}", mapping={
                                'agents': node.agents_count,
                                'health': node.health_score,
                                'latency': node.avg_latency_ms
                            })

            except Exception as e:
                logger.error(f"Erro na coleta de m√©tricas: {e}")

    async def load_balancer(self):
        """
        Balanceamento de carga Hebbiano:
        - N√≥s com alta sinergia (bonds) ficam pr√≥ximos
        - Migra agentes de n√≥s sobrecarregados
        """
        while self.running:
            await asyncio.sleep(10)  # A cada 10 segundos

            if len(self.nodes) < 2:
                continue

            # Calcula carga m√©dia
            active_nodes = [n for n in self.nodes.values() if n.is_active]
            if not active_nodes:
                continue

            avg_load = np.mean([n.agents_count for n in active_nodes])

            # Identifica n√≥s sobrecarregados e subutilizados
            overloaded = [n for n in active_nodes if n.agents_count > avg_load * 1.3]
            underloaded = [n for n in active_nodes if n.agents_count < avg_load * 0.7]

            # Orquestra migra√ß√µes
            for src in overloaded:
                if underloaded:
                    dst = underloaded.pop(0)
                    await self.orchestrate_migration(src, dst)

    async def orchestrate_migration(self, src: ArkheNode, dst: ArkheNode):
        """Orquestra migra√ß√£o de agentes entre n√≥s"""
        # Calcula quantos agentes migrar (Hebbiano: mant√©m bonds)
        migrants = int((src.agents_count - dst.agents_count) * 0.2)

        logger.info(f"üîÑ Migra√ß√£o: {migrants} agentes de {src.node_id} ‚Üí {dst.node_id}")

        # Comando via ZeroMQ
        await self.command_socket.send_json({
            'command': 'MIGRATE_OUT',
            'target_node': dst.node_id,
            'count': migrants,
            'priority': 'hebbian'  # Mant√©m conex√µes sociais
        })

    async def handle_node_failure(self, node_id: str):
        """Lida com falha de n√≥ - realoca agentes"""
        logger.error(f"üî• Falha detectada no n√≥: {node_id}")

        node = self.nodes.get(node_id)
        if not node:
            return

        # Encontra n√≥s vizinhos (parti√ß√µes adjacentes)
        neighbors = self.find_neighbor_partitions(node.partition)

        # Redistribui carga
        for neighbor in neighbors:
            if neighbor.is_active:
                await self.command_socket.send_json({
                    'command': 'ADOPT_PARTITION',
                    'failed_node': node_id,
                    'partition': node.partition
                })
                break

        await self.unregister_node(node_id)

    def find_neighbor_partitions(self, partition: Tuple[int, int, int]) -> List[ArkheNode]:
        """Encontra n√≥s com parti√ß√µes espacialmente adjacentes"""
        # Implementa√ß√£o simplificada: retorna todos os n√≥s ativos
        return [n for n in self.nodes.values() if n.is_active]

    async def get_global_state(self) -> Dict:
        """Retorna estado consolidado de todo o cluster"""
        active_nodes = [n for n in self.nodes.values() if n.is_active]

        return {
            'cluster': {
                'nodes_total': len(self.nodes),
                'nodes_active': len(active_nodes),
                'partitions': [n.partition for n in active_nodes]
            },
            'agents': {
                'total': sum(n.agents_count for n in active_nodes),
                'capacity': sum(n.resources.get('max_agents', 1000) for n in active_nodes),
                'avg_health': np.mean([n.health_score for n in active_nodes]) if active_nodes else 0
            },
            'performance': {
                'avg_latency_ms': np.mean([n.avg_latency_ms for n in active_nodes]) if active_nodes else 0,
                'total_throughput': sum(n.throughput for n in active_nodes)
            }
        }

    async def shutdown(self):
        """Desliga o controller graciosamente"""
        logger.info("üõë Desligando Parallax Controller...")
        self.running = False

        # Notifica todos os n√≥s
        if self.command_socket:
            try:
                await self.command_socket.send_json({
                    'command': 'SHUTDOWN',
                    'reason': 'controller_stop'
                })
            except: pass

        await asyncio.sleep(1)
        if self.command_socket: self.command_socket.close()
        if self.metrics_socket: self.metrics_socket.close()
        self.zmq_context.term()

        if self.redis:
            await self.redis.close()

# FastAPI App para o Controller
controller = ParallaxController()
app = FastAPI(title="Parallax Controller", version="2.0.0")

@app.on_event("startup")
async def startup():
    await controller.initialize()

@app.on_event("shutdown")
async def shutdown_event():
    await controller.shutdown()

@app.get("/health")
async def health():
    return await controller.get_global_state()

@app.post("/nodes/register")
async def register_node(node: ArkheNode):
    success = await controller.register_node(node)
    return {"success": success}

@app.get("/nodes")
async def list_nodes():
    return {
        node_id: {
            'partition': node.partition,
            'agents': node.agents_count,
            'health': node.health_score,
            'active': node.is_active
        }
        for node_id, node in controller.nodes.items()
    }

@app.post("/command/broadcast")
async def broadcast_command(cmd: dict):
    if controller.command_socket:
        await controller.command_socket.send_json(cmd)
        return {"sent": True}
    return {"sent": False, "error": "Command socket not available"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)
